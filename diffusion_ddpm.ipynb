{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Denoising Diffusion Probabilistic Models (DDPM) from Scratch\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adiel2012/deep-learning-abc/blob/main/diffusion_ddpm.ipynb)\n",
                "\n",
                "## 1. Mathematical Foundations\n",
                "\n",
                "Diffusion models are latent variable models of the form $p_\\theta(x_0) := \\int p_\\theta(x_{0:T}) dx_{1:T}$, where $x_1, \\dots, x_T$ are latents of the same dimensionality as the data $x_0$.\n",
                "\n",
                "### Forward Process ($q$)\n",
                "The forward process (diffusion) is a fixed Markov chain that gradually adds Gaussian noise to the data according to a variance schedule $\\beta_1, \\dots, \\beta_T$:\n",
                "\n",
                "$$ q(x_{1:T}|x_0) := \\prod_{t=1}^T q(x_t|x_{t-1}) $$\n",
                "\n",
                "$$ q(x_t|x_{t-1}) := \\mathcal{N}(x_t; \\sqrt{1-\\beta_t} x_{t-1}, \\beta_t \\mathbf{I}) $$\n",
                "\n",
                "A nice property is that we can sample $x_t$ at any arbitrary time step $t$ in closed form. Let $\\alpha_t = 1 - \\beta_t$ and $\\bar{\\alpha}_t = \\prod_{s=1}^t \\alpha_s$:\n",
                "\n",
                "$$ q(x_t|x_0) = \\mathcal{N}(x_t; \\sqrt{\\bar{\\alpha}_t} x_0, (1 - \\bar{\\alpha}_t)\\mathbf{I}) $$\n",
                "\n",
                "### Reverse Process ($p_\\theta$)\n",
                "The reverse process is a learned Markov chain defined as:\n",
                "\n",
                "$$ p_\\theta(x_{0:T}) := p(x_T) \\prod_{t=1}^T p_\\theta(x_{t-1}|x_t) $$\n",
                "\n",
                "$$ p_\\theta(x_{t-1}|x_t) := \\mathcal{N}(x_{t-1}; \\mu_\\theta(x_t, t), \\Sigma_\\theta(x_t, t)) $$\n",
                "\n",
                "We train a model $\\mu_\\theta$ to approximate the posterior mean. In practice, we predict the noise $\\epsilon_\\theta(x_t, t)$.\n",
                "\n",
                "### Training Objective (Simplified ELBO)\n",
                "Ho et al. (2020) showed that the variational lower bound (ELBO) can be simplified to a weighted squared error between the actual noise $\\epsilon$ and the predicted noise $\\epsilon_\\theta$:\n",
                "\n",
                "$$ L_{\\text{simple}}(\\theta) = \\mathbb{E}_{t, x_0, \\epsilon} \\left[ \\| \\epsilon - \\epsilon_\\theta(\\sqrt{\\bar{\\alpha}_t} x_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\epsilon, t) \\|^2 \\right] $$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install torch torchvision matplotlib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torchvision import datasets, transforms\n",
                "from torch.utils.data import DataLoader\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'Using device: {device}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Noise Schedule & Forward Process Implementation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Diffusion:\n",
                "    def __init__(self, T=1000, beta_start=1e-4, beta_end=0.02, img_size=28, device=device):\n",
                "        self.T = T\n",
                "        self.img_size = img_size\n",
                "        self.device = device\n",
                "        \n",
                "        self.beta = torch.linspace(beta_start, beta_end, T).to(device)\n",
                "        self.alpha = 1. - self.beta\n",
                "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
                "\n",
                "    def noise_images(self, x, t):\n",
                "        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n",
                "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n",
                "        epsilon = torch.randn_like(x)\n",
                "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * epsilon, epsilon\n",
                "\n",
                "    def sample_timesteps(self, n):\n",
                "        return torch.randint(low=1, high=self.T, size=(n,), device=self.device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Visualization: Forward Process"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_forward_process(diffusion):\n",
                "    # Load one image\n",
                "    dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
                "    x0, _ = dataset[0]\n",
                "    x0 = x0.unsqueeze(0).to(device)\n",
                "    \n",
                "    plt.figure(figsize=(15, 3))\n",
                "    num_steps = 10\n",
                "    step_size = diffusion.T // num_steps\n",
                "    \n",
                "    for i in range(num_steps):\n",
                "        t = torch.tensor([i * step_size]).to(device)\n",
                "        xt, _ = diffusion.noise_images(x0, t)\n",
                "        \n",
                "        plt.subplot(1, num_steps, i + 1)\n",
                "        plt.imshow(xt.cpu().squeeze(), cmap='gray')\n",
                "        plt.title(f\"t={t.item()}\")\n",
                "        plt.axis('off')\n",
                "    plt.suptitle(\"Forward Diffusion Process: $q(x_t|x_0)$\", fontsize=16)\n",
                "    plt.show()\n",
                "\n",
                "curr_diffusion = Diffusion(device=device)\n",
                "plot_forward_process(curr_diffusion)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Simple U-Net (Noise Predictor)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleUNet(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        # Simplified U-Net for MNIST\n",
                "        self.down1 = nn.Sequential(nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2))\n",
                "        self.down2 = nn.Sequential(nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2))\n",
                "        \n",
                "        self.time_embed = nn.Sequential(nn.Linear(1, 64), nn.ReLU(), nn.Linear(64, 64))\n",
                "        \n",
                "        self.up1 = nn.Upsample(scale_factor=2, mode='nearest')\n",
                "        self.up_conv1 = nn.Sequential(nn.Conv2d(64 + 64, 32, 3, padding=1), nn.ReLU())\n",
                "        self.up2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
                "        self.up_conv2 = nn.Sequential(nn.Conv2d(32, 32, 3, padding=1), nn.ReLU())\n",
                "        \n",
                "        self.out = nn.Conv2d(32, 1, 3, padding=1)\n",
                "\n",
                "    def forward(self, x, t):\n",
                "        # Time embedding\n",
                "        t = t.float().view(-1, 1)\n",
                "        t_emb = self.time_embed(t)[:, :, None, None]\n",
                "        \n",
                "        # Down\n",
                "        x1 = self.down1(x)\n",
                "        x2 = self.down2(x1)\n",
                "        \n",
                "        # Inject time\n",
                "        x2 = x2 + t_emb\n",
                "        \n",
                "        # Up\n",
                "        x = self.up1(x2)\n",
                "        x = torch.cat([x, x1], dim=1)\n",
                "        x = self.up_conv1(x)\n",
                "        \n",
                "        x = self.up2(x)\n",
                "        x = self.up_conv2(x)\n",
                "        \n",
                "        return self.out(x)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Training with Loss Visualization"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
                "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
                "\n",
                "model = SimpleUNet().to(device)\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
                "loss_fn = nn.MSELoss()\n",
                "\n",
                "loss_history = []\n",
                "\n",
                " epochs = 3\n",
                "print(\"Starting Training...\")\n",
                "for epoch in range(epochs):\n",
                "    epoch_loss = 0\n",
                "    for images, _ in dataloader:\n",
                "        images = images.to(device)\n",
                "        t = curr_diffusion.sample_timesteps(images.shape[0])\n",
                "        x_t, noise = curr_diffusion.noise_images(images, t)\n",
                "        \n",
                "        predicted_noise = model(x_t, t)\n",
                "        loss = loss_fn(noise, predicted_noise)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        epoch_loss += loss.item()\n",
                "    \n",
                "    avg_loss = epoch_loss/len(dataloader)\n",
                "    loss_history.append(avg_loss)\n",
                "    print(f\"Epoch {epoch}: Loss {avg_loss:.4f}\")\n",
                "\n",
                "# Plot Loss\n",
                "plt.figure(figsize=(8, 4))\n",
                "plt.plot(loss_history, marker='o')\n",
                "plt.title(\"Training Loss (MSE between $\\epsilon$ and $\\epsilon_\\theta$)\")\n",
                "plt.xlabel(\"Epoch\")\n",
                "plt.ylabel(\"Loss\")\n",
                "plt.grid(True)\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Sampling (Reverse Process)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def sample(model, n, diffusion):\n",
                "    model.eval()\n",
                "    with torch.no_grad():\n",
                "        x = torch.randn((n, 1, 28, 28)).to(device)\n",
                "        for i in reversed(range(1, diffusion.T)):\n",
                "            t = (torch.ones(n) * i).long().to(device)\n",
                "            predicted_noise = model(x, t)\n",
                "            \n",
                "            alpha = diffusion.alpha[t][:, None, None, None]\n",
                "            alpha_hat = diffusion.alpha_hat[t][:, None, None, None]\n",
                "            beta = diffusion.beta[t][:, None, None, None]\n",
                "            \n",
                "            if i > 1:\n",
                "                noise = torch.randn_like(x)\n",
                "            else:\n",
                "                noise = torch.zeros_like(x)\n",
                "                \n",
                "            x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
                "            \n",
                "    model.train()\n",
                "    return x.clamp(0, 1)\n",
                "\n",
                "generated_images = sample(model, 8, curr_diffusion)\n",
                "\n",
                "plt.figure(figsize=(12, 2))\n",
                "for i in range(8):\n",
                "    plt.subplot(1, 8, i+1)\n",
                "    plt.imshow(generated_images[i].cpu().squeeze(), cmap='gray')\n",
                "    plt.axis('off')\n",
                "plt.suptitle(\"Generated Samples via Reverse Diffusion\", fontsize=16)\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}