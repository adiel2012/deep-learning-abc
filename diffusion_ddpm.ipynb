{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Denoising Diffusion Probabilistic Models (DDPM) from Scratch\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adiel2012/deep-learning-abc/blob/main/diffusion_ddpm.ipynb)\n",
                "\n",
                "Diffusion models generate data by reversing a gradual noising process.\n",
                "\n",
                "Key Concepts:\n",
                "1. **Forward Process ($q$):** Gradually add Gaussian noise to an image until it becomes pure noise.\n",
                "2. **Reverse Process ($p_\\theta$):** Learn a neural network (U-Net) to predict the noise added at each step, effectively denoising the image.\n",
                "\n",
                "$$ x_{t-1} = \\frac{1}{\\sqrt{\\alpha_t}} \\left( x_t - \\frac{1-\\alpha_t}{\\sqrt{1-\\bar{\\alpha}_t}} \\epsilon_\\theta(x_t, t) \\right) + \\sigma_t z $$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install torch torchvision matplotlib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torchvision import datasets, transforms\n",
                "from torch.utils.data import DataLoader\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'Using device: {device}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Noise Schedule & Forward Process"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class Diffusion:\n",
                "    def __init__(self, T=1000, beta_start=1e-4, beta_end=0.02, img_size=28, device=device):\n",
                "        self.T = T\n",
                "        self.img_size = img_size\n",
                "        self.device = device\n",
                "        \n",
                "        self.beta = torch.linspace(beta_start, beta_end, T).to(device)\n",
                "        self.alpha = 1. - self.beta\n",
                "        self.alpha_hat = torch.cumprod(self.alpha, dim=0)\n",
                "\n",
                "    def noise_images(self, x, t):\n",
                "        sqrt_alpha_hat = torch.sqrt(self.alpha_hat[t])[:, None, None, None]\n",
                "        sqrt_one_minus_alpha_hat = torch.sqrt(1 - self.alpha_hat[t])[:, None, None, None]\n",
                "        epsilon = torch.randn_like(x)\n",
                "        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * epsilon, epsilon\n",
                "\n",
                "    def sample_timesteps(self, n):\n",
                "        return torch.randint(low=1, high=self.T, size=(n,), device=self.device)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Simple U-Net (Noise Predictor)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SimpleUNet(nn.Module):\n",
                "    def __init__(self):\n",
                "        super().__init__()\n",
                "        # Simplified U-Net for MNIST\n",
                "        self.down1 = nn.Sequential(nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2))\n",
                "        self.down2 = nn.Sequential(nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2))\n",
                "        \n",
                "        self.time_embed = nn.Sequential(nn.Linear(1, 64), nn.ReLU(), nn.Linear(64, 64))\n",
                "        \n",
                "        self.up1 = nn.Upsample(scale_factor=2, mode='nearest')\n",
                "        self.up_conv1 = nn.Sequential(nn.Conv2d(64 + 64, 32, 3, padding=1), nn.ReLU())\n",
                "        self.up2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
                "        self.up_conv2 = nn.Sequential(nn.Conv2d(32, 32, 3, padding=1), nn.ReLU())\n",
                "        \n",
                "        self.out = nn.Conv2d(32, 1, 3, padding=1)\n",
                "\n",
                "    def forward(self, x, t):\n",
                "        # Time embedding\n",
                "        t = t.float().view(-1, 1)\n",
                "        t_emb = self.time_embed(t)[:, :, None, None]\n",
                "        \n",
                "        # Down\n",
                "        x1 = self.down1(x)\n",
                "        x2 = self.down2(x1)\n",
                "        \n",
                "        # Inject time\n",
                "        x2 = x2 + t_emb\n",
                "        \n",
                "        # Up\n",
                "        x = self.up1(x2)\n",
                "        # Concatenate skip connection (resize due to pooling arithmetic)\n",
                "        # Here we just pad for simplicity or ensure dimensions match. \n",
                "        # For 28x28: down1->14x14, down2->7x7. up1->14x14 (matches x1). up2->28x28.\n",
                "        x = torch.cat([x, x1], dim=1)\n",
                "        x = self.up_conv1(x)\n",
                "        \n",
                "        x = self.up2(x)\n",
                "        x = self.up_conv2(x)\n",
                "        \n",
                "        return self.out(x)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "dataset = datasets.MNIST(root=\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
                "dataloader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
                "\n",
                "model = SimpleUNet().to(device)\n",
                "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
                "curr_diffusion = Diffusion(device=device)\n",
                "\n",
                "loss_fn = nn.MSELoss()\n",
                "\n",
                "for epoch in range(3): # Reduced epochs for demo\n",
                "    epoch_loss = 0\n",
                "    for images, _ in dataloader:\n",
                "        images = images.to(device)\n",
                "        t = curr_diffusion.sample_timesteps(images.shape[0])\n",
                "        x_t, noise = curr_diffusion.noise_images(images, t)\n",
                "        \n",
                "        predicted_noise = model(x_t, t)\n",
                "        loss = loss_fn(noise, predicted_noise)\n",
                "        \n",
                "        optimizer.zero_grad()\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        epoch_loss += loss.item()\n",
                "    \n",
                "    print(f\"Epoch {epoch}: Loss {epoch_loss/len(dataloader):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Sampling (Generation)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def sample(model, n, diffusion):\n",
                "    model.eval()\n",
                "    with torch.no_grad():\n",
                "        x = torch.randn((n, 1, 28, 28)).to(device)\n",
                "        for i in reversed(range(1, diffusion.T)):\n",
                "            t = (torch.ones(n) * i).long().to(device)\n",
                "            predicted_noise = model(x, t)\n",
                "            \n",
                "            alpha = diffusion.alpha[t][:, None, None, None]\n",
                "            alpha_hat = diffusion.alpha_hat[t][:, None, None, None]\n",
                "            beta = diffusion.beta[t][:, None, None, None]\n",
                "            \n",
                "            if i > 1:\n",
                "                noise = torch.randn_like(x)\n",
                "            else:\n",
                "                noise = torch.zeros_like(x)\n",
                "                \n",
                "            x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
                "            \n",
                "    model.train()\n",
                "    return x.clamp(0, 1)\n",
                "\n",
                "generated_images = sample(model, 8, curr_diffusion)\n",
                "\n",
                "fig, ax = plt.subplots(1, 8, figsize=(12, 2))\n",
                "for i in range(8):\n",
                "    ax[i].imshow(generated_images[i].cpu().squeeze(), cmap='gray')\n",
                "    ax[i].axis('off')\n",
                "plt.show()"
            ]
        }
    ]
}