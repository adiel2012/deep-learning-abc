{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA: Low-Rank Adaptation from Scratch\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adiel2012/deep-learning-abc/blob/main/lora_fine_tuning.ipynb)\n",
    "\n",
    "This notebook implements LoRA (Low-Rank Adaptation) from scratch — the parameter-efficient fine-tuning method that lets you adapt massive models by training only a tiny fraction of parameters.\n",
    "\n",
    "We cover:\n",
    "1. Why full fine-tuning is expensive\n",
    "2. Low-rank matrix decomposition intuition\n",
    "3. LoRA implementation from raw operations\n",
    "4. Training a LoRA-adapted model\n",
    "5. Adapter merging for zero-overhead inference\n",
    "6. Rank analysis and parameter savings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Mathematical Foundations\n",
    "\n",
    "### The Fine-Tuning Problem\n",
    "\n",
    "A pretrained model has weight matrix $W_0 \\in \\mathbb{R}^{d \\times k}$. Full fine-tuning learns:\n",
    "\n",
    "$$W = W_0 + \\Delta W$$\n",
    "\n",
    "where $\\Delta W \\in \\mathbb{R}^{d \\times k}$ has the same size as $W_0$. For a 7B model, $\\Delta W$ has **billions** of parameters.\n",
    "\n",
    "### LoRA Insight\n",
    "\n",
    "Aghajanyan et al. (2021) showed that pretrained models have **low intrinsic dimensionality** — the weight updates during fine-tuning lie in a low-rank subspace.\n",
    "\n",
    "LoRA (Hu et al., 2021) constrains $\\Delta W$ to be low-rank:\n",
    "\n",
    "$$\\Delta W = B \\cdot A$$\n",
    "\n",
    "where $B \\in \\mathbb{R}^{d \\times r}$ and $A \\in \\mathbb{R}^{r \\times k}$, with $r \\ll \\min(d, k)$.\n",
    "\n",
    "The adapted forward pass becomes:\n",
    "\n",
    "$$h = W_0 x + \\Delta W x = W_0 x + B A x$$\n",
    "\n",
    "### Parameter Savings\n",
    "\n",
    "For $W_0 \\in \\mathbb{R}^{4096 \\times 4096}$:\n",
    "- Full fine-tuning: $4096 \\times 4096 = 16.8M$ parameters\n",
    "- LoRA ($r=16$): $(4096 \\times 16) + (16 \\times 4096) = 131K$ parameters\n",
    "- **Reduction: 128x fewer parameters!**\n",
    "\n",
    "### Initialization\n",
    "\n",
    "- $A$ is initialized with small random values (Gaussian)\n",
    "- $B$ is initialized to **zero** → $\\Delta W = BA = 0$ at start\n",
    "- This ensures the adapted model starts exactly at the pretrained model\n",
    "\n",
    "### Scaling Factor\n",
    "\n",
    "LoRA uses a scaling factor $\\alpha / r$:\n",
    "\n",
    "$$h = W_0 x + \\frac{\\alpha}{r} B A x$$\n",
    "\n",
    "This makes it easier to tune $\\alpha$ independently of $r$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Low-Rank Approximation Intuition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate: weight update matrices are approximately low-rank\n",
    "torch.manual_seed(42)\n",
    "d, k = 64, 64\n",
    "\n",
    "# Simulate: pretrained weights and fine-tuned weights\n",
    "W_pretrained = torch.randn(d, k, device=device)\n",
    "\n",
    "# Simulate fine-tuning: the change is approximately low-rank\n",
    "# (real fine-tuning updates tend to lie in a low-dimensional subspace)\n",
    "true_rank = 4\n",
    "delta_B = torch.randn(d, true_rank, device=device) * 0.1\n",
    "delta_A = torch.randn(true_rank, k, device=device) * 0.1\n",
    "delta_W = delta_B @ delta_A  # rank-4 update\n",
    "delta_W += torch.randn(d, k, device=device) * 0.001  # small noise\n",
    "\n",
    "# Compute SVD to see the rank structure\n",
    "U, S, Vh = torch.linalg.svd(delta_W)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Singular values — sharp drop shows low-rank structure\n",
    "axes[0].bar(range(len(S)), S.cpu().numpy())\n",
    "axes[0].set_xlabel('Singular value index')\n",
    "axes[0].set_ylabel('Magnitude')\n",
    "axes[0].set_title('Singular Values of ΔW\\n(Sharp drop → low-rank structure)')\n",
    "axes[0].axvline(x=true_rank - 0.5, color='red', linestyle='--', label=f'True rank = {true_rank}')\n",
    "axes[0].legend()\n",
    "\n",
    "# Reconstruction error vs rank\n",
    "errors = []\n",
    "for r in range(1, min(d, k) + 1):\n",
    "    approx = U[:, :r] @ torch.diag(S[:r]) @ Vh[:r, :]\n",
    "    err = (delta_W - approx).norm().item() / delta_W.norm().item()\n",
    "    errors.append(err)\n",
    "\n",
    "axes[1].plot(range(1, len(errors) + 1), errors, linewidth=2)\n",
    "axes[1].set_xlabel('Rank of approximation')\n",
    "axes[1].set_ylabel('Relative error')\n",
    "axes[1].set_title('Reconstruction Error vs Rank\\n(rank 4 captures almost everything)')\n",
    "axes[1].axvline(x=true_rank, color='red', linestyle='--', label=f'r = {true_rank}')\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Cumulative energy\n",
    "energy = (S ** 2).cumsum(0) / (S ** 2).sum()\n",
    "axes[2].plot(range(1, len(energy) + 1), energy.cpu().numpy(), linewidth=2)\n",
    "axes[2].set_xlabel('Number of singular values')\n",
    "axes[2].set_ylabel('Fraction of variance explained')\n",
    "axes[2].set_title('Cumulative Variance Explained')\n",
    "axes[2].axhline(y=0.99, color='gray', linestyle='--', alpha=0.5, label='99%')\n",
    "axes[2].axvline(x=true_rank, color='red', linestyle='--', label=f'r = {true_rank}')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LoRA Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_lora(d_in, d_out, rank, alpha=1.0, device=None):\n",
    "    \"\"\"Initialize LoRA adapter matrices.\n",
    "    \n",
    "    Args:\n",
    "        d_in: input dimension\n",
    "        d_out: output dimension  \n",
    "        rank: LoRA rank (r)\n",
    "        alpha: scaling factor\n",
    "    \n",
    "    Returns:\n",
    "        dict with A, B matrices and scaling factor\n",
    "    \"\"\"\n",
    "    lora = {\n",
    "        'A': torch.randn(rank, d_in, device=device) * (1 / math.sqrt(d_in)),  # Kaiming-like\n",
    "        'B': torch.zeros(d_out, rank, device=device),  # Zero init → ΔW = 0 at start\n",
    "        'scaling': alpha / rank,\n",
    "    }\n",
    "    # Mark as trainable (requires_grad)\n",
    "    lora['A'].requires_grad_(True)\n",
    "    lora['B'].requires_grad_(True)\n",
    "    return lora\n",
    "\n",
    "def lora_forward(x, W_frozen, lora):\n",
    "    \"\"\"Forward pass through a LoRA-adapted linear layer.\n",
    "    \n",
    "    h = W_frozen @ x + (scaling * B @ A) @ x\n",
    "    \"\"\"\n",
    "    # Original frozen path\n",
    "    h = x @ W_frozen.T\n",
    "    \n",
    "    # LoRA adapter path\n",
    "    # Efficient: compute A@x first (small), then B@(Ax)\n",
    "    lora_out = x @ lora['A'].T  # (..., rank)  — project to low rank\n",
    "    lora_out = lora_out @ lora['B'].T  # (..., d_out) — project back up\n",
    "    \n",
    "    return h + lora['scaling'] * lora_out\n",
    "\n",
    "# Test\n",
    "torch.manual_seed(42)\n",
    "d_in, d_out = 64, 64\n",
    "rank = 4\n",
    "\n",
    "# Pretrained (frozen) weight\n",
    "W_frozen = torch.randn(d_out, d_in, device=device) * 0.1\n",
    "W_frozen.requires_grad_(False)  # Frozen!\n",
    "\n",
    "# LoRA adapter\n",
    "lora = init_lora(d_in, d_out, rank, alpha=8.0, device=device)\n",
    "\n",
    "# Forward pass\n",
    "x = torch.randn(2, 8, d_in, device=device)\n",
    "out = lora_forward(x, W_frozen, lora)\n",
    "\n",
    "print(f'Input shape: {x.shape}')\n",
    "print(f'Output shape: {out.shape}')\n",
    "print(f'\\nParameter count:')\n",
    "print(f'  Frozen W: {d_in * d_out} (NOT trained)')\n",
    "print(f'  LoRA A:   {rank * d_in}')\n",
    "print(f'  LoRA B:   {d_out * rank}')\n",
    "print(f'  Total trainable: {rank * d_in + d_out * rank}')\n",
    "print(f'  Reduction: {d_in * d_out / (rank * d_in + d_out * rank):.1f}x fewer trainable params')\n",
    "print(f'\\nAt initialization (B=0), ΔW is zero:')\n",
    "delta_W = lora['scaling'] * (lora['B'] @ lora['A'])\n",
    "print(f'  ||ΔW|| = {delta_W.norm().item():.10f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Training a LoRA-Adapted Model\n",
    "\n",
    "Let's train a small transformer layer with LoRA on a simple pattern-learning task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple task: learn to shift a pattern\n",
    "torch.manual_seed(42)\n",
    "d_model = 32\n",
    "seq_len = 8\n",
    "n_samples = 200\n",
    "rank = 4\n",
    "\n",
    "# Pretrained model: a simple linear layer (frozen)\n",
    "W_pretrained = torch.randn(d_model, d_model, device=device) * 0.1\n",
    "W_pretrained.requires_grad_(False)\n",
    "\n",
    "# Task data: input → target (a nonlinear transformation)\n",
    "X_data = torch.randn(n_samples, seq_len, d_model, device=device)\n",
    "\n",
    "# Target: a specific low-rank transformation of input\n",
    "W_target_B = torch.randn(d_model, 4, device=device) * 0.3\n",
    "W_target_A = torch.randn(4, d_model, device=device) * 0.3\n",
    "Y_data = X_data @ W_pretrained.T + X_data @ W_target_A.T @ W_target_B.T\n",
    "Y_data = Y_data.detach()\n",
    "\n",
    "print(f'Task: learn a rank-4 update to a frozen {d_model}x{d_model} weight matrix')\n",
    "print(f'Training data: {n_samples} samples, seq_len={seq_len}, d_model={d_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with LoRA\n",
    "lora_adapter = init_lora(d_model, d_model, rank=rank, alpha=8.0, device=device)\n",
    "lr = 0.01\n",
    "n_epochs = 100\n",
    "\n",
    "losses_lora = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    # Forward\n",
    "    Y_pred = lora_forward(X_data, W_pretrained, lora_adapter)\n",
    "    loss = ((Y_pred - Y_data) ** 2).mean()\n",
    "    losses_lora.append(loss.item())\n",
    "    \n",
    "    # Backward\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update only LoRA parameters (W_pretrained is frozen)\n",
    "    with torch.no_grad():\n",
    "        lora_adapter['A'] -= lr * lora_adapter['A'].grad\n",
    "        lora_adapter['B'] -= lr * lora_adapter['B'].grad\n",
    "        lora_adapter['A'].grad.zero_()\n",
    "        lora_adapter['B'].grad.zero_()\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f'Epoch {epoch:3d}: loss = {loss.item():.6f}')\n",
    "\n",
    "print(f'\\nFinal loss: {losses_lora[-1]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare: full fine-tuning with same data\n",
    "W_full = W_pretrained.clone().detach().requires_grad_(True)\n",
    "losses_full = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    Y_pred = X_data @ W_full.T\n",
    "    loss = ((Y_pred - Y_data) ** 2).mean()\n",
    "    losses_full.append(loss.item())\n",
    "    \n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        W_full -= lr * W_full.grad\n",
    "        W_full.grad.zero_()\n",
    "\n",
    "print(f'Full fine-tuning final loss: {losses_full[-1]:.6f}')\n",
    "print(f'LoRA (rank={rank}) final loss: {losses_lora[-1]:.6f}')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(losses_full, linewidth=2, label=f'Full fine-tuning ({d_model*d_model} params)')\n",
    "ax.plot(losses_lora, linewidth=2, label=f'LoRA rank={rank} ({rank*d_model*2} params)')\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('MSE Loss')\n",
    "ax.set_title('LoRA vs Full Fine-Tuning')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_yscale('log')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nLoRA uses {d_model*d_model / (rank*d_model*2):.1f}x fewer trainable parameters')\n",
    "print(f'and achieves comparable loss on this low-rank task!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Adapter Merging — Zero-Cost Inference\n",
    "\n",
    "After training, LoRA adapters can be **merged** into the frozen weights for zero additional inference cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_lora(W_frozen, lora):\n",
    "    \"\"\"Merge LoRA adapter into frozen weights.\n",
    "    \n",
    "    W_merged = W_frozen + scaling * B @ A\n",
    "    \n",
    "    After merging, inference uses a single matrix multiply — no overhead.\n",
    "    \"\"\"\n",
    "    delta_W = lora['scaling'] * (lora['B'] @ lora['A'])\n",
    "    return W_frozen + delta_W\n",
    "\n",
    "def unmerge_lora(W_merged, W_frozen, lora):\n",
    "    \"\"\"Reverse: extract LoRA from merged weights (to swap adapters).\"\"\"\n",
    "    return W_merged - lora['scaling'] * (lora['B'] @ lora['A'])\n",
    "\n",
    "# Merge and verify\n",
    "W_merged = merge_lora(W_pretrained, lora_adapter)\n",
    "\n",
    "# Forward with separate LoRA\n",
    "x_test = torch.randn(1, 4, d_model, device=device)\n",
    "out_separate = lora_forward(x_test, W_pretrained, lora_adapter)\n",
    "\n",
    "# Forward with merged weights (single matmul — no overhead!)\n",
    "out_merged = x_test @ W_merged.T\n",
    "\n",
    "print('Verification: separate LoRA vs merged weights')\n",
    "print(f'  Max difference: {(out_separate - out_merged).abs().max().item():.2e}')\n",
    "print(f'  Are equal: {torch.allclose(out_separate, out_merged, atol=1e-5)}')\n",
    "\n",
    "print(f'\\nInference cost:')\n",
    "print(f'  With LoRA:  2 matmuls (frozen W + adapter B@A@x)')\n",
    "print(f'  Merged:     1 matmul (same cost as original model!)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the learned ΔW and its rank structure\n",
    "delta_W_learned = lora_adapter['scaling'] * (lora_adapter['B'] @ lora_adapter['A'])\n",
    "U, S, Vh = torch.linalg.svd(delta_W_learned.detach())\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# The learned ΔW\n",
    "im = axes[0].imshow(delta_W_learned.detach().cpu().numpy(), cmap='RdBu', aspect='auto')\n",
    "axes[0].set_title(f'Learned ΔW = B @ A\\n(rank = {rank})')\n",
    "axes[0].set_xlabel('Input dim')\n",
    "axes[0].set_ylabel('Output dim')\n",
    "plt.colorbar(im, ax=axes[0])\n",
    "\n",
    "# Singular values show the rank\n",
    "axes[1].bar(range(min(20, len(S))), S[:20].cpu().numpy())\n",
    "axes[1].set_xlabel('Singular value index')\n",
    "axes[1].set_ylabel('Magnitude')\n",
    "axes[1].set_title(f'Singular Values of Learned ΔW\\n(exactly rank {rank})')\n",
    "axes[1].axvline(x=rank - 0.5, color='red', linestyle='--', label=f'Rank boundary (r={rank})')\n",
    "axes[1].legend()\n",
    "\n",
    "# Comparison with full fine-tuning update\n",
    "delta_full = (W_full - W_pretrained).detach()\n",
    "U_f, S_f, _ = torch.linalg.svd(delta_full)\n",
    "axes[2].bar(range(min(20, len(S_f))), S_f[:20].cpu().numpy(), alpha=0.6, label='Full FT ΔW')\n",
    "axes[2].bar(range(min(20, len(S))), S[:20].cpu().numpy(), alpha=0.6, label=f'LoRA ΔW (r={rank})')\n",
    "axes[2].set_xlabel('Singular value index')\n",
    "axes[2].set_ylabel('Magnitude')\n",
    "axes[2].set_title('ΔW Rank: Full vs LoRA')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Effect of Rank\n",
    "\n",
    "How does the choice of rank $r$ affect LoRA performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LoRA with different ranks\n",
    "ranks = [1, 2, 4, 8, 16, 32]\n",
    "final_losses = []\n",
    "param_counts = []\n",
    "\n",
    "for r in ranks:\n",
    "    torch.manual_seed(42)\n",
    "    lora_r = init_lora(d_model, d_model, rank=r, alpha=8.0, device=device)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        Y_pred = lora_forward(X_data, W_pretrained, lora_r)\n",
    "        loss = ((Y_pred - Y_data) ** 2).mean()\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            lora_r['A'] -= lr * lora_r['A'].grad\n",
    "            lora_r['B'] -= lr * lora_r['B'].grad\n",
    "            lora_r['A'].grad.zero_()\n",
    "            lora_r['B'].grad.zero_()\n",
    "    \n",
    "    final_losses.append(loss.item())\n",
    "    param_counts.append(r * d_model * 2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(ranks, final_losses, 'o-', linewidth=2, markersize=8)\n",
    "axes[0].set_xlabel('LoRA Rank (r)')\n",
    "axes[0].set_ylabel('Final Loss')\n",
    "axes[0].set_title('Loss vs LoRA Rank')\n",
    "axes[0].set_yscale('log')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].axvline(x=4, color='red', linestyle='--', alpha=0.5, label='True rank of target = 4')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].plot(param_counts, final_losses, 'o-', linewidth=2, markersize=8)\n",
    "axes[1].set_xlabel('Trainable Parameters')\n",
    "axes[1].set_ylabel('Final Loss')\n",
    "axes[1].set_title('Loss vs Parameter Count')\n",
    "axes[1].set_yscale('log')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "full_params = d_model * d_model\n",
    "axes[1].axvline(x=full_params, color='gray', linestyle='--', alpha=0.5, label=f'Full FT ({full_params} params)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Rank vs Final Loss:')\n",
    "for r, l, p in zip(ranks, final_losses, param_counts):\n",
    "    print(f'  r={r:2d}: loss={l:.6f}, params={p:5d} ({100*p/full_params:.1f}% of full)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Multi-Adapter Switching\n",
    "\n",
    "A key advantage of LoRA: you can train multiple adapters for different tasks and swap them efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate multiple task-specific adapters on the same base model\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Base model (shared, frozen)\n",
    "W_base = torch.randn(d_model, d_model, device=device) * 0.1\n",
    "\n",
    "# Task A adapter: translate-like (shift pattern)\n",
    "lora_task_A = init_lora(d_model, d_model, rank=4, alpha=8.0, device=device)\n",
    "with torch.no_grad():\n",
    "    lora_task_A['B'][:, 0] = torch.randn(d_model, device=device) * 0.5\n",
    "    lora_task_A['A'][0, :] = torch.randn(d_model, device=device) * 0.5\n",
    "\n",
    "# Task B adapter: scale-like (different transformation)\n",
    "lora_task_B = init_lora(d_model, d_model, rank=4, alpha=8.0, device=device)\n",
    "with torch.no_grad():\n",
    "    lora_task_B['B'][:, 0] = torch.randn(d_model, device=device) * 0.3\n",
    "    lora_task_B['A'][0, :] = -torch.randn(d_model, device=device) * 0.3\n",
    "\n",
    "x_test = torch.randn(1, 4, d_model, device=device)\n",
    "\n",
    "# Switch adapters — just change which A,B you use!\n",
    "out_base = x_test @ W_base.T\n",
    "out_A = lora_forward(x_test, W_base, lora_task_A)\n",
    "out_B = lora_forward(x_test, W_base, lora_task_B)\n",
    "\n",
    "print('Multi-adapter switching:')\n",
    "print(f'  Base model output norm:  {out_base.norm().item():.4f}')\n",
    "print(f'  + Task A adapter norm:   {out_A.norm().item():.4f}')\n",
    "print(f'  + Task B adapter norm:   {out_B.norm().item():.4f}')\n",
    "print(f'\\nAdapter storage per task: {4 * d_model * 2 * 4 / 1024:.1f} KB (rank=4, d_model={d_model}, float32)')\n",
    "print(f'Base model storage:       {d_model * d_model * 4 / 1024:.1f} KB')\n",
    "print(f'\\n→ Store one base model + tiny adapters for each task!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Real-world parameter savings\n",
    "print('=' * 70)\n",
    "print('PARAMETER SAVINGS: LoRA at Scale')\n",
    "print('=' * 70)\n",
    "\n",
    "model_configs = [\n",
    "    ('7B (LLaMA)', 4096, 32),\n",
    "    ('13B', 5120, 40),\n",
    "    ('70B', 8192, 80),\n",
    "]\n",
    "\n",
    "lora_ranks = [4, 8, 16, 64]\n",
    "\n",
    "for model_name, d, n_layers in model_configs:\n",
    "    print(f'\\n{model_name} (d_model={d}, {n_layers} layers):')\n",
    "    # Each layer has W_Q, W_K, W_V, W_O — LoRA typically on Q and V\n",
    "    n_adapted_matrices = 2 * n_layers  # Q and V per layer\n",
    "    full_params = n_adapted_matrices * d * d\n",
    "    print(f'  Full fine-tuning (Q,V only): {full_params/1e6:.1f}M params')\n",
    "    \n",
    "    for r in lora_ranks:\n",
    "        lora_params = n_adapted_matrices * (r * d + d * r)\n",
    "        reduction = full_params / lora_params\n",
    "        print(f'  LoRA r={r:2d}: {lora_params/1e6:>8.2f}M params ({reduction:>6.0f}x reduction)')\n",
    "\n",
    "print('\\n' + '=' * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we implemented from scratch:\n",
    "\n",
    "1. **Low-rank approximation** — weight updates during fine-tuning lie in a low-dimensional subspace\n",
    "\n",
    "2. **LoRA adapters** — decompose $\\Delta W = BA$ where $B \\in \\mathbb{R}^{d \\times r}$, $A \\in \\mathbb{R}^{r \\times d}$, $r \\ll d$\n",
    "\n",
    "3. **Training** — only A and B are updated; base model stays frozen\n",
    "\n",
    "4. **Adapter merging** — $W_{\\text{merged}} = W_0 + \\frac{\\alpha}{r}BA$ gives zero-overhead inference\n",
    "\n",
    "5. **Multi-task switching** — store one base model + tiny adapters per task\n",
    "\n",
    "**Key insight:** Pretrained models live in a low-dimensional subspace. LoRA exploits this to reduce trainable parameters by 100-1000x while maintaining quality. This makes fine-tuning accessible: a 65B model can be adapted on a single GPU with QLoRA."
   ]
  }
 ]
}