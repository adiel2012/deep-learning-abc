{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Variational Autoencoders (VAE) from Scratch\n",
                "\n",
                "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/adiel2012/deep-learning-abc/blob/main/vae.ipynb)\n",
                "\n",
                "VAEs learn a latent variable model by maximizing the Evidence Lower Bound (ELBO).\n",
                "\n",
                "Key Concepts:\n",
                "1. **Encoder:** Maps input $x$ to latent distribution parameters $\\mu, \\sigma$ (approximate posterior $q_\\phi(z|x)$).\n",
                "2. **Reparameterization Trick:** Sample $z = \\mu + \\sigma \\cdot \\epsilon$ where $\\epsilon \\sim \\mathcal{N}(0, 1)$. This allows backpropagation through stochastic sampling.\n",
                "3. **Decoder:** Maps $z$ back to $x$ (likelihood $p_\\theta(x|z)$).\n",
                "\n",
                "Loss = Reconstruction Loss - KL Divergence"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install torch torchvision matplotlib"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "import torch.optim as optim\n",
                "from torchvision import datasets, transforms\n",
                "from torch.utils.data import DataLoader\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "print(f'Using device: {device}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. VAE Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class VAE(nn.Module):\n",
                "    def __init__(self, img_dim=28*28, h_dim=400, z_dim=20):\n",
                "        super().__init__()\n",
                "        # Encoder\n",
                "        self.fc1 = nn.Linear(img_dim, h_dim)\n",
                "        self.fc2_mu = nn.Linear(h_dim, z_dim)\n",
                "        self.fc2_logvar = nn.Linear(h_dim, z_dim)\n",
                "        \n",
                "        # Decoder\n",
                "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
                "        self.fc4 = nn.Linear(h_dim, img_dim)\n",
                "\n",
                "    def encode(self, x):\n",
                "        h = F.relu(self.fc1(x))\n",
                "        return self.fc2_mu(h), self.fc2_logvar(h)\n",
                "\n",
                "    def reparameterize(self, mu, logvar):\n",
                "        if self.training:\n",
                "            std = torch.exp(0.5 * logvar)\n",
                "            eps = torch.randn_like(std)\n",
                "            return mu + eps * std\n",
                "        else:\n",
                "            return mu\n",
                "\n",
                "    def decode(self, z):\n",
                "        h = F.relu(self.fc3(z))\n",
                "        return torch.sigmoid(self.fc4(h))  # Output probabilities [0, 1]\n",
                "\n",
                "    def forward(self, x):\n",
                "        mu, logvar = self.encode(x.view(-1, 784))\n",
                "        z = self.reparameterize(mu, logvar)\n",
                "        return self.decode(z), mu, logvar"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Loss Function (ELBO)\n",
                "\n",
                "$$ \\mathcal{L} = \\underbrace{\\mathbb{E}_{q}[\\log p(x|z)]}_{\\text{Reconstruction}} - \\underbrace{D_{KL}(q(z|x) || p(z))}_{\\text{Regularization}} $$"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def loss_function(recon_x, x, mu, logvar):\n",
                "    # 1. Reconstruction Loss (Binary Cross Entropy)\n",
                "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
                "    \n",
                "    # 2. KL Divergence: KL(N(mu, sigma) || N(0, 1))\n",
                "    # = -0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
                "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
                "    \n",
                "    return BCE + KLD\n",
                "\n",
                "# Data & Training\n",
                "dataset = datasets.MNIST(root=\"dataset/\", transform=transforms.ToTensor(), download=True)\n",
                "loader = DataLoader(dataset, batch_size=128, shuffle=True)\n",
                "\n",
                "model = VAE().to(device)\n",
                "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
                "\n",
                "print(\"Training VAE...\")\n",
                "model.train()\n",
                "for epoch in range(5):\n",
                "    total_loss = 0\n",
                "    for batch_idx, (data, _) in enumerate(loader):\n",
                "        data = data.to(device)\n",
                "        optimizer.zero_grad()\n",
                "        \n",
                "        recon_batch, mu, logvar = model(data)\n",
                "        loss = loss_function(recon_batch, data, mu, logvar)\n",
                "        \n",
                "        loss.backward()\n",
                "        total_loss += loss.item()\n",
                "        optimizer.step()\n",
                "        \n",
                "    print(f\"Epoch {epoch}: Average Loss {total_loss / len(loader.dataset):.4f}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Manifold Learning (Visualizing Latent Space)\n",
                "\n",
                "Since we forced $z$\n",
                "to be close to Gaussian, we can sample from the latent space to generate new digits."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with torch.no_grad():\n",
                "    # Sample random points from standard normal\n",
                "    z = torch.randn(16, 20).to(device)\n",
                "    sample = model.decode(z).cpu()\n",
                "    \n",
                "    # Plot\n",
                "    fig, axes = plt.subplots(2, 8, figsize=(10, 3))\n",
                "    for i, ax in enumerate(axes.flatten()):\n",
                "        ax.imshow(sample[i].view(28, 28), cmap='gray')\n",
                "        ax.axis('off')\n",
                "    plt.suptitle('VAE Generated Digits (sampled from N(0,1))')\n",
                "    plt.show()"
            ]
        }
    ]
}